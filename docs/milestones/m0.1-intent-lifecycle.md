# M0.1: Intent Lifecycle, IDs, and Observability Seed

* Goals

  * Lock the canonical **intent lifecycle** and identifiers.
  * Stamp **`server_tick`** everywhere.
  * Seed **observability + mini-replay** to protect determinism/idempotency later.

* Deliverables

  * **Lifecycle states**: `RECEIVED → ACCEPTED → IN_PROGRESS → BLOCKED? → FINISHED | CANCELED | REJECTED`.
    Each event includes: `intent_id`, `client_cmd_id`, `player_id`, `server_tick`; failures include `reason`.
  * **Identifiers**

    * `client_cmd_id`: 16-byte UUIDv7 from client.
    * `intent_id`: UUIDv7 or monotonic per player (server-assigned).
    * `client_seq`: per-player sequence number (client-maintained).
    * `server_tick`: strictly monotonic; attached to deltas and lifecycle events.
  * **Wire/Streams (Redis)**

    * `rts:match:{id}:intents` — client → engine (XADD; consumer group on engine).
    * `rts:match:{id}:events` — engine → client (lifecycle events, deltas, metrics).
    * `rts:match:{id}:snapshots` — periodic world snapshots.
    * Payloads are **protobuf**; optional tiny JSON envelope for devtools readability.
  * **Protocol header**

    * `protocol_version (semver)`, `content_version (hash)` echoed in handshake logs (client & server).
  * **Mini-replay script** (`pnpm demo:replay:lastN`)

    * Replays the last N intents against an in-memory engine and asserts final world hash (`xxh3` over sorted entity state).
  * **Latency probe CLI**

    * Send 100 `Move` intents; report p50/p95 from submit → first delta that references that `intent_id`.

* Acceptance Criteria

  * Lifecycle events produced for `Move` with all IDs + `server_tick`; UI can ignore them, logs must show them.
  * Applying the same delta twice on a cloned world yields the same world hash (idempotency smoke test).
  * Mini-replay of the last N intents yields identical final world hash to live world.
  * Latency probe prints p50/p95 to console and writes one JSON metrics file per run.

# Implementation Details

- **Lifecycle states**
  - Extend `packages/schemas/proto/intent.proto` with `IntentLifecycleEvent` / `IntentLifecycleState`, then regenerate via `pnpm --filter @bitwars/schemas run gen:ts`. (No `apps/engine` directory exists; Rust engine code lives under `services/rts-engine/`.)
  - Add a lifecycle publisher in `services/rts-engine/src/engine/intent.rs` or a new sibling module (e.g., `services/rts-engine/src/engine/lifecycle.rs`) that owns event construction from `IntentManager` state and publishes via the existing Redis client in `services/rts-engine/src/io/redis.rs`.
  - Store last-known lifecycle state in Redis using hashes (`intent:{intent_id}`) within `services/rts-engine/src/io/redis.rs`, alongside the current stream writes (`publish_intent` / `read_new_intents`).
  - Update the `Move` flow in `services/rts-engine/src/engine/intent.rs` so the log-only transitions become structured events (`RECEIVED`, `ACCEPTED`, `IN_PROGRESS`, `FINISHED`), and map failure paths to `BLOCKED`/`CANCELED`/`REJECTED` with populated `reason` strings.

- **Identifiers**
  - Update `services/rts-engine/src/engine/mod.rs` ingestion loop to enforce UUIDv7 `client_cmd_id` + monotonic `client_seq`, caching recently seen `(player_id, client_cmd_id)` keys using Redis (extend `services/rts-engine/src/io/redis.rs` with a `SETEX`).
  - Generate `intent_id` server-side when decoding intents in `services/rts-engine/src/engine/mod.rs` and include it in lifecycle events; we may emit it back to Redis streams via new helper functions in `services/rts-engine/src/io/redis.rs`.
  - Add shared utilities under `packages/shared/src/ids.ts` (currently directory exists but file is new) so the Next.js client (`apps/web`) and future tooling can format/validate IDs consistently.

- **Server tick stamping**
  - Expose a single tick accessor inside `services/rts-engine/src/engine/mod.rs` (e.g., `self.state.tick`) and pass it into the lifecycle publisher so deltas and lifecycle events share the same value; there is no separate `serverTick.ts` today.
  - Add Rust unit/integration tests under `services/rts-engine/src/engine/` verifying that serialized deltas and lifecycle events include identical `server_tick` values.

- **Wire/Streams (Redis)**
  - Add provisioning logic either as a Rust admin task in `services/rts-engine/src/io/redis.rs` or a Node script under `scripts/` (no `tools/` directory currently). Streams today use `intents:{id}` / `deltas:{id}` in `RedisClient`; align new names by updating that module and the web SSE route at `apps/web/src/app/api/v2/gamestate/stream/route.ts`.
  - Lifecycle envelopes should be protobuf-only; consider adding a dev-only JSON wrapper flag handled in the client utilities at `apps/web/src/lib/db/utils/redis-streams.ts` (currently exists) rather than a global env var.
  - Ensure the Next.js stream reader in `apps/web/src/app/api/v2/gamestate/stream/route.ts` acknowledges events only after replay success; current implementation tails with `xReadWithBuffers` and will need adjustments once lifecycle events are added.

- **Protocol header**
  - Introduce a new schema (`packages/schemas/proto/protocol.proto` does not exist yet) or extend an existing handshake message once identified; neither server nor client currently performs a handshake—future work will likely touch `services/rts-engine/src/main.rs` and a forthcoming websocket/SSE bootstrap in `apps/web`.
  - When client handshake code appears, place logging + storage in `apps/web/src/lib/` (no existing `socket/handshake.ts` file). Note this is a planned addition rather than an edit to existing code.

- **Mini-replay script (`pnpm demo:replay:lastN`)**
  - Add a new workspace package (e.g., `apps/replay-tool/` or `scripts/replay-last-n.ts`) since no `apps/tools/` directory exists. Leverage shared protobuf types from `packages/shared/src/gen/` and reuse Redis helpers from `apps/web/src/lib/db/utils/redis-streams.ts`.
  - Support CLI flags `--match`, `--count`, `--snapshot`; bootstrap initial world state by reading `snapshot:{id}` via existing `redis` crate helpers or Node clients.
  - Output hash comparisons and non-zero exit codes to allow CI integration.

- **Latency probe CLI**
  - Stand up a CLI either as a Node script under `scripts/latency-probe.ts` or a Rust binary inside `services/rts-engine/src/bin/` (no `apps/tools/` directory to host it today).
  - Use existing Redis stream utilities (`services/rts-engine/src/io/redis.rs` for Rust or `apps/web/src/lib/db/utils/redis-streams.ts` for TS) to publish intents and observe lifecycle events once they exist.
  - Emit histogram metrics to `.metrics/m0.1/` (create directory at repo root) and enforce a timeout to catch failures quickly.
